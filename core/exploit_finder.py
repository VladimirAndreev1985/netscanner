"""Exploit finder â€” search PoC on GitHub, Exploit-DB, PacketStorm."""

import asyncio
import json
import logging
import subprocess
import shutil

import aiohttp

from core.device import Device

logger = logging.getLogger("netscanner.exploit_finder")


async def find_exploits(device: Device) -> list[dict]:
    """Find available exploits for device vulnerabilities."""
    results = []
    cve_ids = [v.cve_id for v in device.vulnerabilities if v.cve_id]

    if not cve_ids:
        return results

    tasks = []
    for cve_id in cve_ids:
        tasks.append(_search_github_poc(cve_id))
        tasks.append(_search_exploitdb(cve_id))

    all_results = await asyncio.gather(*tasks, return_exceptions=True)

    for result in all_results:
        if isinstance(result, list):
            results.extend(result)
        elif isinstance(result, Exception):
            logger.debug(f"Exploit search failed: {result}")

    # Deduplicate by URL
    seen = set()
    unique = []
    for r in results:
        if r.get("url") not in seen:
            seen.add(r.get("url"))
            unique.append(r)

    return unique


async def _search_github_poc(cve_id: str) -> list[dict]:
    """Search GitHub for PoC exploits by CVE ID."""
    results = []
    search_url = "https://api.github.com/search/repositories"
    params = {
        "q": cve_id,
        "sort": "stars",
        "order": "desc",
        "per_page": 5,
    }

    try:
        timeout = aiohttp.ClientTimeout(total=15)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(search_url, params=params) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    for repo in data.get("items", []):
                        results.append({
                            "cve_id": cve_id,
                            "source": "GitHub",
                            "name": repo.get("full_name", ""),
                            "description": (repo.get("description") or "")[:200],
                            "url": repo.get("html_url", ""),
                            "stars": repo.get("stargazers_count", 0),
                            "language": repo.get("language", ""),
                            "updated": repo.get("updated_at", ""),
                            "type": "poc",
                        })
                elif resp.status == 403:
                    logger.warning("GitHub API rate limit exceeded")
    except Exception as e:
        logger.debug(f"GitHub search failed for {cve_id}: {e}")

    return results


async def _search_exploitdb(cve_id: str) -> list[dict]:
    """Search Exploit-DB via searchsploit."""
    results = []
    if not shutil.which("searchsploit"):
        return results

    cve_num = cve_id.replace("CVE-", "")
    loop = asyncio.get_event_loop()

    try:
        def run_searchsploit():
            return subprocess.run(
                ["searchsploit", "--cve", cve_num, "-j"],
                capture_output=True, text=True, timeout=15,
            )

        result = await loop.run_in_executor(None, run_searchsploit)

        if result.returncode == 0 and result.stdout.strip():
            data = json.loads(result.stdout)
            for exploit in data.get("RESULTS_EXPLOIT", []):
                results.append({
                    "cve_id": cve_id,
                    "source": "Exploit-DB",
                    "name": exploit.get("Title", ""),
                    "description": exploit.get("Title", ""),
                    "url": f"https://www.exploit-db.com/exploits/{exploit.get('EDB-ID', '')}",
                    "path": exploit.get("Path", ""),
                    "type": exploit.get("Type", ""),
                    "platform": exploit.get("Platform", ""),
                })
    except (subprocess.TimeoutExpired, json.JSONDecodeError) as e:
        logger.debug(f"searchsploit failed for {cve_id}: {e}")

    return results


async def search_by_keyword(keyword: str) -> list[dict]:
    """Search for exploits by keyword (brand, model, etc.)."""
    results = []

    # GitHub search
    try:
        search_url = "https://api.github.com/search/repositories"
        params = {
            "q": f"{keyword} exploit OR poc OR vulnerability",
            "sort": "stars",
            "order": "desc",
            "per_page": 10,
        }
        timeout = aiohttp.ClientTimeout(total=15)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(search_url, params=params) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    for repo in data.get("items", []):
                        results.append({
                            "source": "GitHub",
                            "name": repo.get("full_name", ""),
                            "description": (repo.get("description") or "")[:200],
                            "url": repo.get("html_url", ""),
                            "stars": repo.get("stargazers_count", 0),
                            "type": "poc",
                        })
    except Exception as e:
        logger.debug(f"GitHub keyword search failed: {e}")

    # searchsploit keyword search
    if shutil.which("searchsploit"):
        try:
            result = subprocess.run(
                ["searchsploit", keyword, "-j"],
                capture_output=True, text=True, timeout=15,
            )
            if result.returncode == 0 and result.stdout.strip():
                data = json.loads(result.stdout)
                for exploit in data.get("RESULTS_EXPLOIT", [])[:10]:
                    results.append({
                        "source": "Exploit-DB",
                        "name": exploit.get("Title", ""),
                        "url": f"https://www.exploit-db.com/exploits/{exploit.get('EDB-ID', '')}",
                        "path": exploit.get("Path", ""),
                        "type": exploit.get("Type", ""),
                    })
        except (subprocess.TimeoutExpired, json.JSONDecodeError):
            pass

    return results
